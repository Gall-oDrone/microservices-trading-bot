{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d092e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click==8.0.4 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.11.2 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.11.2)\n",
      "Requirement already satisfied: boto3>=1.28.17 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.28.18)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.0.3)\n",
      "Requirement already satisfied: psycopg2>=2.9.6 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.9.6)\n",
      "Requirement already satisfied: psycopg2-binary>=2.9.4 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.9.7)\n",
      "Requirement already satisfied: webdriver-manager==3.8.5 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.8.5)\n",
      "Requirement already satisfied: importlib-metadata==4.8.3 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (4.8.3)\n",
      "Requirement already satisfied: itsdangerous==2.0.1 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: Jinja2==3.0.3 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe==2.0.1 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions==4.1.1 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (4.1.1)\n",
      "Requirement already satisfied: Werkzeug==2.0.3 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (2.0.3)\n",
      "Requirement already satisfied: zipp==3.6.0 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (3.6.0)\n",
      "Requirement already satisfied: future>=0.18.3 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.18.3)\n",
      "Requirement already satisfied: selenium>=4.8.0 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from beautifulsoup4==4.11.2->-r requirements.txt (line 2)) (2.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from webdriver-manager==3.8.5->-r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from webdriver-manager==3.8.5->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from webdriver-manager==3.8.5->-r requirements.txt (line 7)) (4.65.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from webdriver-manager==3.8.5->-r requirements.txt (line 7)) (23.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.18 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from boto3>=1.28.17->-r requirements.txt (line 3)) (1.31.18)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from boto3>=1.28.17->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from boto3>=1.28.17->-r requirements.txt (line 3)) (0.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from pandas>=2.0.3->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from pandas>=2.0.3->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from pandas>=2.0.3->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from pandas>=2.0.3->-r requirements.txt (line 4)) (1.25.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from selenium>=4.8.0->-r requirements.txt (line 16)) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from selenium>=4.8.0->-r requirements.txt (line 16)) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from selenium>=4.8.0->-r requirements.txt (line 16)) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from selenium>=4.8.0->-r requirements.txt (line 16)) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from trio~=0.17->selenium>=4.8.0->-r requirements.txt (line 16)) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from trio~=0.17->selenium>=4.8.0->-r requirements.txt (line 16)) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from trio~=0.17->selenium>=4.8.0->-r requirements.txt (line 16)) (3.4)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from trio~=0.17->selenium>=4.8.0->-r requirements.txt (line 16)) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from trio~=0.17->selenium>=4.8.0->-r requirements.txt (line 16)) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium>=4.8.0->-r requirements.txt (line 16)) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium>=4.8.0->-r requirements.txt (line 16)) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.8.0->-r requirements.txt (line 16)) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from requests->webdriver-manager==3.8.5->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/envs/flask1/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.8.0->-r requirements.txt (line 16)) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2aac37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    basestring\n",
    "except NameError:\n",
    "    basestring = str\n",
    "\n",
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "from future.utils import iteritems\n",
    "import dateutil.parser\n",
    "\n",
    "class BaseModel(object):\n",
    "\n",
    "    \"\"\" Base class for other models. \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self._default_params = {}\n",
    "\n",
    "    @classmethod\n",
    "    def _NewFromJsonDict(cls, data, **kwargs):\n",
    "        if kwargs:\n",
    "            for key, val in kwargs.items():\n",
    "                data[key] = val\n",
    "        return cls(**data)\n",
    "\n",
    "class Book(BaseModel):\n",
    "    \"\"\"A class that represents the Bitso orderbook and it's limits\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self._default_params = {\n",
    "            'symbol': kwargs.get('book'),\n",
    "            'minimum_amount': Decimal(kwargs.get('minimum_amount')),\n",
    "            'maximum_amount': Decimal(kwargs.get('maximum_amount')),\n",
    "            'minimum_price': Decimal(kwargs.get('minimum_price')),\n",
    "            'maximum_price': Decimal(kwargs.get('maximum_price')),\n",
    "            'minimum_value': Decimal(kwargs.get('minimum_value')),\n",
    "            'maximum_value': Decimal(kwargs.get('maximum_value'))\n",
    "        }\n",
    "        \n",
    "        for (param, val) in self._default_params.items():\n",
    "            setattr(self, param, val)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Book(symbol={symbol})\".format(symbol=self.symbol)\n",
    "    \n",
    "class AvailableBooks(BaseModel):\n",
    "    \"\"\"A class that represents Bitso's orderbooks\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.books = []\n",
    "        for ob in kwargs.get('payload'):\n",
    "            self.books.append(ob['book'])\n",
    "            setattr(self, ob['book'], Book._NewFromJsonDict(ob))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AvilableBooks(books={books})\".format(books=','.join(self.books))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c58bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#\n",
    "#The MIT License (MIT)\n",
    "#\n",
    "#Copyright (c) 2016 Mario Romero \n",
    "#\n",
    "#Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "#of this software and associated documentation files (the \"Software\"), to deal\n",
    "#in the Software without restriction, including without limitation the rights\n",
    "#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "#copies of the Software, and to permit persons to whom the Software is\n",
    "#furnished to do so, subject to the following conditions:\n",
    "#\n",
    "#The above copyright notice and this permission notice shall be included in all\n",
    "#copies or substantial portions of the Software.\n",
    "#\n",
    "#THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "#SOFTWARE.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from future.utils import iteritems\n",
    "\n",
    "try:\n",
    "    from urllib.parse import urlparse, urlencode\n",
    "except ImportError:\n",
    "    from urlparse import urlparse\n",
    "    from urllib import urlencode\n",
    "\n",
    "def current_milli_time():\n",
    "    nonce =  str(int(round(time.time() * 1000000)))\n",
    "    return nonce\n",
    "\n",
    "class ApiError(Exception):\n",
    "    pass\n",
    "\n",
    "class ApiClientError(Exception):\n",
    "    pass\n",
    "\n",
    "class Api(object):\n",
    "    \"\"\"A python interface for the Bitso API\n",
    "\n",
    "    Example usage:\n",
    "      To create an instance of the bitso.Api class, without authentication:\n",
    "      \n",
    "        >>> import bitso\n",
    "        >>> api = bitso.Api()\n",
    "      \n",
    "      To get the Bitso price ticker:\n",
    "      \n",
    "        >>> ticker = api.ticker()\n",
    "        >>> print ticker.ask\n",
    "        >>> print ticker.bid\n",
    "\n",
    "      To use the private endpoints, initiate bitso.Api with a client_id,\n",
    "      api_key, and api_secret (see https://bitso.com/developers?shell#private-endpoints):\n",
    "      \n",
    "        >>> api = bitso.Api(API_KEY, API_SECRET)\n",
    "        >>> balance = api.balance()\n",
    "        >>> print balance.btc_available\n",
    "        >>> print balance.mxn_available\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, key=None, secret=None, timeout=0):\n",
    "        \"\"\"Instantiate a bitso.Api object.\n",
    "        \n",
    "        Args:\n",
    "          key:\n",
    "            Bitso API Key \n",
    "          secret:\n",
    "            Bitso API Secret\n",
    "\n",
    "  \n",
    "        \"\"\"\n",
    "        self.base_url_v2 = \"https://bitso.com/api/v2\"\n",
    "        self.base_url = \"https://bitso.com/api/v3\"\n",
    "        self.key = key\n",
    "        self._secret = secret\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def available_books(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "          A list of bitso.AvilableBook instances\n",
    "        \"\"\"\n",
    "        url = '%s/available_books/' % self.base_url\n",
    "        resp = self._request_url(url, 'GET')\n",
    "        return AvailableBooks._NewFromJsonDict(resp)\n",
    "    \n",
    "    def _build_auth_payload(self):\n",
    "        parameters = {}\n",
    "        parameters['key'] = self.key\n",
    "        parameters['nonce'] = str(int(time.time()))\n",
    "        msg_concat = parameters['nonce']+self.client_id+self.key\n",
    "        parameters['signature'] = hmac.new(self._secret.encode('utf-8'),\n",
    "                                           msg_concat.encode('utf-8'),\n",
    "                                           hashlib.sha256).hexdigest()\n",
    "        return parameters\n",
    "\n",
    "    def _build_auth_header(self, http_method, url, json_payload=''):\n",
    "        if json_payload == {} or json_payload=='{}':\n",
    "            json_payload = ''\n",
    "        url_components = urlparse(url)\n",
    "        request_path = url_components.path\n",
    "        if url_components.query != '':\n",
    "            request_path+='?'+url_components.query\n",
    "        nonce = current_milli_time()\n",
    "        msg_concat = nonce+http_method.upper()+request_path+json_payload\n",
    "        signature = hmac.new(self._secret.encode('utf-8'),\n",
    "                                 msg_concat.encode('utf-8'),\n",
    "                                 hashlib.sha256).hexdigest()\n",
    "        return {'Authorization': 'Bitso %s:%s:%s' % (self.key, nonce, signature)}\n",
    "\n",
    "    \n",
    "    def _request_url(self, url, verb, params=None, private=False):\n",
    "        headers=None\n",
    "        if params == None:\n",
    "            params = {}\n",
    "        params = {k: v.decode(\"utf-8\") if isinstance(v, bytes) else v for k, v in params.items()}\n",
    "        if private:\n",
    "            headers = self._build_auth_header(verb, url, json.dumps(params))\n",
    "        if verb == 'GET':\n",
    "            url = self._build_url(url, params)\n",
    "            if private:\n",
    "                headers = self._build_auth_header(verb, url)\n",
    "            try:\n",
    "                resp = requests.get(url, headers=headers, timeout=self.timeout)\n",
    "            except requests.RequestException as e:\n",
    "                raise\n",
    "        elif verb == 'POST':\n",
    "            try:\n",
    "                resp = requests.post(url, json=params, headers=headers, timeout=self.timeout)\n",
    "            except requests.RequestException as e:\n",
    "                raise\n",
    "        elif verb == 'DELETE':\n",
    "            try:\n",
    "                resp = requests.delete(url, headers=headers, timeout=self.timeout)\n",
    "            except requests.RequestException as e:\n",
    "                raise\n",
    "        content = resp.content\n",
    "        data = self._parse_json(content if isinstance(content, basestring) else content.decode('utf-8'))\n",
    "        return data\n",
    "\n",
    "    def _build_url(self, url, params):\n",
    "        if params and len(params) > 0:\n",
    "            url = url+'?'+self._encode_parameters(params)\n",
    "        return url\n",
    "\n",
    "    def _encode_parameters(self, parameters):\n",
    "        if parameters is None:\n",
    "            return None\n",
    "        else:\n",
    "            param_tuples = []\n",
    "            for k,v in parameters.items():\n",
    "                if v is None:\n",
    "                    continue\n",
    "                if isinstance(v, (list, tuple)):\n",
    "                    for single_v in v:\n",
    "                        param_tuples.append((k, single_v))\n",
    "                else:\n",
    "                    param_tuples.append((k,v))\n",
    "            return urlencode(param_tuples)\n",
    "\n",
    "\n",
    "         \n",
    "    def _parse_json(self, json_data):\n",
    "        try:\n",
    "            data = json.loads(json_data)\n",
    "            self._check_for_api_error(data)\n",
    "        except:\n",
    "            raise\n",
    "        return data\n",
    "\n",
    "    def _check_for_api_error(self, data):\n",
    "        if data['success'] != True:\n",
    "            raise ApiError(data['error'])\n",
    "        if 'error' in data:\n",
    "            raise ApiError(data['error'])\n",
    "        if isinstance(data, (list, tuple)) and len(data)>0:\n",
    "            if 'error' in data[0]:\n",
    "                raise ApiError(data[0]['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3967877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Available Books: 97\n",
      "Available Books: ['btc_mxn', 'eth_mxn', 'xrp_mxn', 'ltc_mxn', 'bch_mxn', 'tusd_btc', 'tusd_mxn', 'mana_mxn', 'bat_mxn', 'btc_ars', 'btc_dai', 'dai_mxn', 'btc_usd', 'xrp_usd', 'eth_usd', 'dai_ars', 'btc_brl', 'eth_ars', 'eth_brl', 'btc_usdt', 'usd_mxn', 'usd_ars', 'usd_brl', 'mana_usd', 'ltc_usd', 'comp_usd', 'link_usd', 'uni_usd', 'aave_usd', 'chz_usd', 'btc_cop', 'axs_usd', 'dydx_usd', 'yfi_usd', 'sand_usd', 'shib_usd', 'snx_usd', 'matic_usd', 'mkr_usd', 'enj_usd', 'ftm_usd', 'crv_usd', 'gala_usd', 'ada_usd', 'lrc_usd', 'grt_usd', 'ape_usd', 'sushi_usd', 'omg_usd', 'sol_usd', 'dot_usd', 'qnt_usd', 'doge_usd', 'eth_cop', 'xrp_cop', 'usd_cop', 'bal_usd', 'trx_usd', 'algo_usd', 'ldo_usd', 'xlm_usd', 'matic_brl', 'ada_brl', 'sol_brl', 'xrp_brl', 'doge_brl', 'chz_brl', 'usdt_brl', 'paxg_usd', 'shib_brl', 'avax_usd', 'eur_mxn', 'tigres_mxn', 'usdt_cop', 'eur_brl', 'dot_brl', 'ltc_brl', 'link_brl', 'tigres_usd', 'uni_brl', 'mana_brl', 'bch_brl', 'bat_usd', 'bch_usd', 'usdt_mxn', 'eth_btc', 'bar_usd', 'usdt_ars', 'psg_usd', 'atom_usd', 'near_usd', 'usd_usdt', 'avax_mxn', 'sol_mxn', 'trx_mxn', 'matic_mxn', 'pepe_usd']\n"
     ]
    }
   ],
   "source": [
    "api = Api(timeout=5)\n",
    "avb_books = api.available_books()\n",
    "print(f\"Total Available Books: {len(avb_books.books)}\")\n",
    "print(f\"Available Books: {avb_books.books}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed81df4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total USD Available Books: 80\n",
      "USD Available Books: ['tusd_btc', 'btc_ars', 'btc_dai', 'btc_usd', 'xrp_usd', 'eth_usd', 'dai_ars', 'btc_brl', 'eth_ars', 'eth_brl', 'btc_usdt', 'usd_ars', 'usd_brl', 'mana_usd', 'ltc_usd', 'comp_usd', 'link_usd', 'uni_usd', 'aave_usd', 'chz_usd', 'btc_cop', 'axs_usd', 'dydx_usd', 'yfi_usd', 'sand_usd', 'shib_usd', 'snx_usd', 'matic_usd', 'mkr_usd', 'enj_usd', 'ftm_usd', 'crv_usd', 'gala_usd', 'ada_usd', 'lrc_usd', 'grt_usd', 'ape_usd', 'sushi_usd', 'omg_usd', 'sol_usd', 'dot_usd', 'qnt_usd', 'doge_usd', 'eth_cop', 'xrp_cop', 'usd_cop', 'bal_usd', 'trx_usd', 'algo_usd', 'ldo_usd', 'xlm_usd', 'matic_brl', 'ada_brl', 'sol_brl', 'xrp_brl', 'doge_brl', 'chz_brl', 'usdt_brl', 'paxg_usd', 'shib_brl', 'avax_usd', 'usdt_cop', 'eur_brl', 'dot_brl', 'ltc_brl', 'link_brl', 'tigres_usd', 'uni_brl', 'mana_brl', 'bch_brl', 'bat_usd', 'bch_usd', 'eth_btc', 'bar_usd', 'usdt_ars', 'psg_usd', 'atom_usd', 'near_usd', 'usd_usdt', 'pepe_usd']\n"
     ]
    }
   ],
   "source": [
    "usd_books = [book for book in avb_books.books if 'mxn' not in book]\n",
    "print(f\"Total USD Available Books: {len(usd_books)}\")\n",
    "print(f\"USD Available Books: {usd_books}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2fe3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USD Available Books: ['tusd-btc', 'btc-ars', 'btc-dai', 'btc-usd', 'xrp-usd', 'eth-usd', 'dai-ars', 'btc-brl', 'eth-ars', 'eth-brl', 'btc-usdt', 'usd-ars', 'usd-brl', 'mana-usd', 'ltc-usd', 'comp-usd', 'link-usd', 'uni-usd', 'aave-usd', 'chz-usd', 'btc-cop', 'axs-usd', 'dydx-usd', 'yfi-usd', 'sand-usd', 'shib-usd', 'snx-usd', 'matic-usd', 'mkr-usd', 'enj-usd', 'ftm-usd', 'crv-usd', 'gala-usd', 'ada-usd', 'lrc-usd', 'grt-usd', 'ape-usd', 'sushi-usd', 'omg-usd', 'sol-usd', 'dot-usd', 'qnt-usd', 'doge-usd', 'eth-cop', 'xrp-cop', 'usd-cop', 'bal-usd', 'trx-usd', 'algo-usd', 'ldo-usd', 'xlm-usd', 'matic-brl', 'ada-brl', 'sol-brl', 'xrp-brl', 'doge-brl', 'chz-brl', 'usdt-brl', 'paxg-usd', 'shib-brl', 'avax-usd', 'usdt-cop', 'eur-brl', 'dot-brl', 'ltc-brl', 'link-brl', 'tigres-usd', 'uni-brl', 'mana-brl', 'bch-brl', 'bat-usd', 'bch-usd', 'eth-btc', 'bar-usd', 'usdt-ars', 'psg-usd', 'atom-usd', 'near-usd', 'usd-usdt', 'pepe-usd']\n"
     ]
    }
   ],
   "source": [
    "usd_books = [book.replace('_', '-') for book in usd_books]\n",
    "print(f\"USD Available Books: {usd_books}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69bd2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_book(book):\n",
    "    cum = []\n",
    "    start = False\n",
    "    for usd_book in usd_books:\n",
    "        if usd_book == book:\n",
    "            start = True\n",
    "        if start:\n",
    "            cum.append(usd_book)\n",
    "    print(f\"From chosen USD Available Book: {cum}\")\n",
    "    return cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d797998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "\n",
    "def create_connection():\n",
    "    # Replace these placeholders with your actual database credentials\n",
    "    '''\n",
    "    dbname = os.environ['DB_NAME']\n",
    "    user = os.environ['DB_USER']\n",
    "    password = os.environ['DB_PASSWORD']\n",
    "    host = os.environ['DB_HOST']  # Change to your database host if it's not local\n",
    "    port = os.environ['DB_PORT']\n",
    "    '''\n",
    "    dbname = \"cryptostocks\"\n",
    "    user = \"postgres\"\n",
    "    password = \"gallo\"\n",
    "    host = \"localhost\"  # Change to your database host if it's not local\n",
    "    port = \"5432\"  # Change to your database port if it's not the default (5432)\n",
    "\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            dbname=dbname,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host,\n",
    "            port=port\n",
    "        )\n",
    "        print(\"Connection to the database successful!\")\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Unable to connect to the database. {e}\")\n",
    "        return None\n",
    "\n",
    "def create_table(connection):\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        # Define your table schema here\n",
    "        create_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS historical (\n",
    "                reference VARCHAR(255),\n",
    "                book VARCHAR(255),\n",
    "                date DATE,\n",
    "                open FLOAT,\n",
    "                high FLOAT,\n",
    "                low FLOAT,\n",
    "                close FLOAT,\n",
    "                adj_close FLOAT,\n",
    "                volume BIGINT\n",
    "            )\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(create_table_query)\n",
    "        connection.commit()\n",
    "        print(\"Table created successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Unable to create the table. {e}\")\n",
    "    cursor.close()\n",
    "\n",
    "def delete_table(table_name, conn):\n",
    "    # Create a cursor to execute SQL commands\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Generate the SQL DROP TABLE statement\n",
    "        drop_table_sql = f\"DROP TABLE IF EXISTS {table_name}\"\n",
    "\n",
    "        # Execute the DROP TABLE statement\n",
    "        cursor.execute(drop_table_sql)\n",
    "\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "        print(f\"The table '{table_name}' has been deleted successfully.\")\n",
    "    except Error as e:\n",
    "        # If an error occurs, print the error message\n",
    "        print(\"Error:\", e)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        # Close the cursor\n",
    "        cursor.close()\n",
    "\n",
    "        \n",
    "def save_to_postgres(row_data, header, conn):\n",
    "    cursor = conn.cursor()\n",
    "    # Create a dictionary to map header to data in the current row\n",
    "    row_dict = dict(zip(header, row_data))\n",
    "\n",
    "    # Generate the SQL INSERT statement\n",
    "    insert_sql = \"INSERT INTO historical ({}) VALUES ({}) ON CONFLICT DO NOTHING\".format(\n",
    "        \", \".join(row_dict.keys()),\n",
    "        \", \".join(\"%s\" for _ in range(len(row_dict)))\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Execute the SQL query with row_data as the values to be inserted\n",
    "        cursor.execute(insert_sql, list(row_dict.values()))\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        # If an error occurs, print the error message and roll back the transaction\n",
    "        print(\"error on saving data to pg:\", e, \"\\n row_dict:\", row_dict)\n",
    "        conn.rollback()\n",
    "    cursor.close()\n",
    "\n",
    "def init_db():\n",
    "    # Connect to the database\n",
    "    connection = create_connection()\n",
    "    if not connection:\n",
    "        return\n",
    "\n",
    "    # Create the table (if not exists)\n",
    "    create_table(connection)\n",
    "    return connection\n",
    "\n",
    "def close_connection(conn):\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb08fdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to the database successful!\n",
      "Table created successfully!\n"
     ]
    }
   ],
   "source": [
    "conn = init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67166706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import remoteStorage as rs\n",
    "import boto3\n",
    "\n",
    "def store_to_s3(bucket_name, folder_name):\n",
    "    # Bucket name and folder paths\n",
    "    local_file_path = \"path/to/local/file.txt\"\n",
    "    s3_file_path = f\"{folder_name}/file.txt\"\n",
    "\n",
    "    # Create the bucket and folder if they don't exist\n",
    "    rs.create_bucket(bucket_name)\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    bucket.put_object(Key=s3_file_path, Body=\"\")  # Create an empty object to create the folder\n",
    "\n",
    "    # Upload the file to S3\n",
    "    rs.upload_file_to_s3(bucket_name, local_file_path, s3_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e1f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9285510",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "url = f'https://finance.yahoo.com/lookup'\n",
    "xpath = \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/div/div/div/ul/li[1]/div/div/div[2]/h3/a\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37b53aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HISTORIAL_DATA_BTN = \"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[7]/div/div/section/div/ul/li[4]/a\"\n",
    "\n",
    "TBODY = \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/section/div[2]/table/tbody\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "990e47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_date(date_str):\n",
    "    # Convert the month name to a numerical representation using a dictionary\n",
    "    month_dict = {\n",
    "        \"Jan\": \"01\",\n",
    "        \"Feb\": \"02\",\n",
    "        \"Mar\": \"03\",\n",
    "        \"Apr\": \"04\",\n",
    "        \"May\": \"05\",\n",
    "        \"Jun\": \"06\",\n",
    "        \"Jul\": \"07\",\n",
    "        \"Aug\": \"08\",\n",
    "        \"Sep\": \"09\",\n",
    "        \"Oct\": \"10\",\n",
    "        \"Nov\": \"11\",\n",
    "        \"Dec\": \"12\",\n",
    "    }\n",
    "\n",
    "    date_str = date_str.replace(\",\", \"\")\n",
    "\n",
    "    # Split the date string into month, day, and year\n",
    "    month, day, year = date_str.split()\n",
    "\n",
    "    # Get the numerical representation of the month from the dictionary\n",
    "    month_number = month_dict[month]\n",
    "\n",
    "    # Create a new date string in the format 'year-month-day' (e.g., '2023-08-01')\n",
    "    formatted_date_str = f\"{year}-{month_number}-{day}\"\n",
    "\n",
    "    # Parse the formatted date string to a datetime object\n",
    "    parsed_date = datetime.strptime(formatted_date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    return parsed_date\n",
    "\n",
    "def parse_row_data(row_data):\n",
    "    try:\n",
    "        date_format = '%Y-%m-%d'  # Format for parsing date strings\n",
    "\n",
    "        # Remove commas from numeric values\n",
    "        row_data = [item.replace(\",\", \"\") if isinstance(item, str) else item for item in row_data]\n",
    "\n",
    "        # Parse elements at specific positions into desired data types\n",
    "        row_data[0] = parse_date(row_data[0])\n",
    "        row_data[1] = float(row_data[1])\n",
    "        row_data[2] = float(row_data[2])\n",
    "        row_data[3] = float(row_data[3])\n",
    "        row_data[4] = float(row_data[4])\n",
    "        row_data[5] = float(row_data[5])\n",
    "        row_data[6] = int(row_data[6])\n",
    "        return row_data\n",
    "    except Exception as e:\n",
    "        print(\"error during parsing data:\", e, \"row_data: \", row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78adff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def save_unavailable_book(book_name):\n",
    "    try:\n",
    "        current_directory = os.getcwd()\n",
    "        unavailable_books_file = os.path.join(current_directory, \"unavailable_books.csv\")\n",
    "        \n",
    "        file_exists = os.path.isfile(unavailable_books_file)\n",
    "        with open(unavailable_books_file, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            if not file_exists:\n",
    "                writer.writerow([\"book\"])  # Add header if the file is newly created\n",
    "            writer.writerow([book_name])\n",
    "        print(f\"Book '{book_name}' added to unavailable_books.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while saving book '{book_name}' to CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437f5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_url(ticker, period1=1410825600, period2=1690675200, interval=\"1d\",adjclose=\"true\"):\n",
    "    return f'https://finance.yahoo.com/quote/{ticker.upper()}/history?period1={period1}&period2={period2}&interval={interval}&filter=history&frequency={interval}&includeAdjustedClose={adjclose}'\n",
    "\n",
    "def scroll_to_bottom(driver):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    \n",
    "def is_at_bottom(driver):\n",
    "    lastHeight = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"var scrollingElement = (document.scrollingElement || document.body);scrollingElement.scrollTop = scrollingElement.scrollHeight;\")\n",
    "        height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        driver.execute_script(\"window.scrollTo(0, \" + str(height) + \");\")\n",
    "        time.sleep(2)\n",
    "        if lastHeight == height:\n",
    "            print(\"scrolling down task finished\")\n",
    "            break\n",
    "        lastHeight = height\n",
    "\n",
    "def check_tab_header(driver):\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, '//*[@id=\"quote-nav\"]')\n",
    "        #tab = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[7]/section/div/ul/li[3]/a')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"financial header or historical data tab does not exist: {e}\")\n",
    "        return False\n",
    "    \n",
    "def nomatchresult(driver):\n",
    "    wait = WebDriverWait(driver, 3.0)\n",
    "    el = '/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[1]/div/div/section/section/div/div/span/span'\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, el)))\n",
    "        match_result = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[1]/div/div/section/section/div/div/span/span\")\n",
    "        print(f\"output: {match_result.text.lower()}\")\n",
    "        return \"No results for\".lower() in match_result.text.lower()\n",
    "    except Exception as nse:\n",
    "            print(\"queried book was found!\")\n",
    "            return False\n",
    "            \n",
    "def lookup_ticker(driver, ticker):\n",
    "    RejectAll= driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[3]/div[2]/div/div/div/div/div/div[1]/div/div/div/form/input')\n",
    "    action = ActionChains(driver)\n",
    "    action.click(on_element = RejectAll)\n",
    "    action.perform()\n",
    "    time.sleep(5)\n",
    "    SearchBar = driver.find_element(By.ID, \"yfin-usr-qry\")\n",
    "    SearchBar.send_keys(ticker.upper())\n",
    "    SearchBar.send_keys(Keys.ENTER)\n",
    "\n",
    "def select_historical_li(driver):\n",
    "    li_historical_a = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[7]/div/div/section/div/ul/li[4]/a')\n",
    "    action = ActionChains(driver)\n",
    "    action.click(on_element = li_historical_a)\n",
    "    action.perform()\n",
    "    time.sleep(3)\n",
    "\n",
    "def disable_ad(driver): \n",
    "    wait = WebDriverWait(driver, 3.0)\n",
    "    try:\n",
    "        ad_element = '//*[@id=\"Col1-0-Ad-Proxy\"]'\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, ad_element)))\n",
    "        driver.execute_script(\"arguments[0].style.display = 'none';\", ad_element)\n",
    "    except Exception as e:\n",
    "        print(\"ad element was not found\")\n",
    "\n",
    "def search_selector(driver):\n",
    "    wait = WebDriverWait(driver, 3.0)\n",
    "    try:\n",
    "        selector1 = \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/section\"\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, selector1)))\n",
    "        return selector1\n",
    "    except Exception as e:\n",
    "        print(\"selector1 for time period not found trying the second\")\n",
    "        try:\n",
    "            selector2 = \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/div/div/section\"\n",
    "            wait.until(EC.presence_of_element_located((By.XPATH, selector2)))\n",
    "            return selector2\n",
    "        except Exception as e:\n",
    "            print(\"selector2 for time period not found\")\n",
    "            \n",
    "def select_historical(driver, freq):  \n",
    "    print(\"historical data selection task started\")\n",
    "    disable_ad(driver)\n",
    "    se = search_selector(driver)\n",
    "    period_dropdown_div = driver.find_element(By.XPATH, f\"{se}/div[1]/div[1]/div[1]/div/div/div[1]\")\n",
    "    action = ActionChains(driver)\n",
    "    period_dropdown_div.click()\n",
    "    time.sleep(3)\n",
    "    if freq == 'daily':\n",
    "        max_p_btn = driver.find_element(By.XPATH, f\"{se}/div[1]/div[1]/div[1]/div/div/div[2]/div/ul[1]/li[1]/button\")\n",
    "        max_p_btn.click()\n",
    "    else:\n",
    "        max_p_btn = driver.find_element(By.XPATH, f\"{se}/div[1]/div[1]/div[1]/div/div/div[2]/div/ul[2]/li[4]/button\")\n",
    "        max_p_btn.click()\n",
    "    time.sleep(3)\n",
    "    apply_btn = driver.find_element(By.XPATH, f\"{se}/div[1]/div[1]/button\")\n",
    "    apply_btn.click()\n",
    "    print(\"historical data selection task finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c03729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 8.29M/8.29M [00:04<00:00, 2.08MB/s]\n"
     ]
    }
   ],
   "source": [
    "DRIVER_PATH= \"/chromedriver/chromedriver\"\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.90 Safari/537.36\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--proxy-server='direct://'\")\n",
    "options.add_argument(\"--proxy-bypass-list=*\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "service = Service(ChromeDriverManager(version='114.0.5735.90').install())\n",
    "driver =  webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: tusd-btc\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: btc-ars\n",
      "output: no results for 'btc-ars'\n",
      "skipping to next ticket\n",
      "Book 'btc-ars' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: btc-dai\n",
      "output: no results for 'btc-dai'\n",
      "skipping to next ticket\n",
      "Book 'btc-dai' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: btc-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: xrp-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: eth-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: dai-ars\n",
      "output: no results for 'dai-ars'\n",
      "skipping to next ticket\n",
      "Book 'dai-ars' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: btc-brl\n",
      "output: no results for 'btc-brl'\n",
      "skipping to next ticket\n",
      "Book 'btc-brl' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: eth-ars\n",
      "output: no results for 'eth-ars'\n",
      "skipping to next ticket\n",
      "Book 'eth-ars' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: eth-brl\n",
      "output: no results for 'eth-brl'\n",
      "skipping to next ticket\n",
      "Book 'eth-brl' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: btc-usdt\n",
      "queried book was found!\n",
      "financial header or historical data tab does not exist: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"quote-nav\"]\"}\n",
      "  (Session info: headless chrome=115.0.5790.170); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010b3626b8 chromedriver + 4937400\n",
      "1   chromedriver                        0x000000010b359b73 chromedriver + 4901747\n",
      "2   chromedriver                        0x000000010af17616 chromedriver + 435734\n",
      "3   chromedriver                        0x000000010af5ae0f chromedriver + 712207\n",
      "4   chromedriver                        0x000000010af5b0a1 chromedriver + 712865\n",
      "5   chromedriver                        0x000000010af9c9a4 chromedriver + 981412\n",
      "6   chromedriver                        0x000000010af7f03d chromedriver + 860221\n",
      "7   chromedriver                        0x000000010af99e76 chromedriver + 970358\n",
      "8   chromedriver                        0x000000010af7ede3 chromedriver + 859619\n",
      "9   chromedriver                        0x000000010af4cd7f chromedriver + 654719\n",
      "10  chromedriver                        0x000000010af4e0de chromedriver + 659678\n",
      "11  chromedriver                        0x000000010b31e2ad chromedriver + 4657837\n",
      "12  chromedriver                        0x000000010b323130 chromedriver + 4677936\n",
      "13  chromedriver                        0x000000010b329def chromedriver + 4705775\n",
      "14  chromedriver                        0x000000010b32405a chromedriver + 4681818\n",
      "15  chromedriver                        0x000000010b2f692c chromedriver + 4495660\n",
      "16  chromedriver                        0x000000010b341838 chromedriver + 4802616\n",
      "17  chromedriver                        0x000000010b3419b7 chromedriver + 4802999\n",
      "18  chromedriver                        0x000000010b35299f chromedriver + 4872607\n",
      "19  libsystem_pthread.dylib             0x00007ff80b2ca4e1 _pthread_start + 125\n",
      "20  libsystem_pthread.dylib             0x00007ff80b2c5f6b thread_start + 15\n",
      "\n",
      "skipping to next ticket\n",
      "Book 'btc-usdt' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: usd-ars\n",
      "output: no results for 'usd-ars'\n",
      "skipping to next ticket\n",
      "Book 'usd-ars' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: usd-brl\n",
      "output: no results for 'usd-brl'\n",
      "skipping to next ticket\n",
      "Book 'usd-brl' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: mana-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: ltc-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: comp-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: link-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: uni-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: aave-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: chz-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: btc-cop\n",
      "output: no results for 'btc-cop'\n",
      "skipping to next ticket\n",
      "Book 'btc-cop' added to unavailable_books.csv\n",
      "====================================================================\n",
      "Book: axs-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: dydx-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: yfi-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: sand-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: shib-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: snx-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: matic-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: mkr-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: enj-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: ftm-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: crv-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: gala-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: ada-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: lrc-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: grt-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: ape-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: sushi-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: omg-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n",
      "historical data selection task finished\n",
      "scrolling down task finished\n",
      "scraping data task started\n",
      "scraping data task finished\n",
      "====================================================================\n",
      "Book: sol-usd\n",
      "queried book was found!\n",
      "historical data selection task started\n",
      "ad element was not found\n",
      "selector1 for time period not found trying the second\n"
     ]
    }
   ],
   "source": [
    "REFERENCE = 'https://finance.yahoo.com'\n",
    "Header = [\"reference\", \"book\", \"date\", \"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\"]\n",
    "n = len(Header)\n",
    "Debug = False\n",
    "freq = 'daily'\n",
    "# Create a DataFrame using Pandas\n",
    "#df = pd.DataFrame(columns=Header)\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver,5).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "    try:\n",
    "        for book in usd_books:\n",
    "            print(f'Book: {book}')\n",
    "            # TO-CHECK pepe-usd, paxg-usd\n",
    "            target_url = f\"https://finance.yahoo.com/quote/{book.upper()}/history?p={book.upper()}\"\n",
    "            driver.get(target_url)\n",
    "            \n",
    "            lookup_url = f\"https://finance.yahoo.com/lookup?s={book.upper()}\"\n",
    "            while driver.current_url != target_url:\n",
    "                driver.get(target_url)\n",
    "                time.sleep(3) \n",
    "                if(lookup_url == driver.current_url):\n",
    "                    break\n",
    "        \n",
    "            if(nomatchresult(driver) or not check_tab_header(driver)):\n",
    "                print(\"skipping to next ticket\")\n",
    "                # save_unavailable_book(book)\n",
    "                print(\"====================================================================\")\n",
    "                continue\n",
    "            select_historical(driver, freq)\n",
    "            time.sleep(1)\n",
    "\n",
    "            is_at_bottom(driver)\n",
    "            table = driver.find_element(By.XPATH, TBODY)\n",
    "            # Get all rows of the table\n",
    "            rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "            # Create an empty list to store the table data\n",
    "            #table_data = []\n",
    "            #df_book = pd.DataFrame(table_data, columns=Header)\n",
    "            # Iterate through each row\n",
    "            print(\"scraping data task started\")\n",
    "            for row in rows:\n",
    "                # Get all columns (cells) of the row\n",
    "                columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                row_data = []\n",
    "                row_data = [column.text for column in columns if column.text != '-']\n",
    "                if(len(row_data) != 7):\n",
    "                    print(\"skipping to next row\")\n",
    "                    continue\n",
    "                row_data = parse_row_data(row_data)\n",
    "                row_data.insert(0, book)\n",
    "                row_data.insert(0, REFERENCE)\n",
    "                save_to_postgres(row_data, Header, conn)\n",
    "                #df_book = pd.concat([df_book, pd.DataFrame([row_data], columns=Header)], ignore_index=True)\n",
    "            #df = pd.concat([df, df_book], ignore_index=True)\n",
    "            #num_rows, num_columns = df.shape\n",
    "            #last_five_rows = df.tail(3)\n",
    "            print(\"scraping data task finished\")\n",
    "            print(\"====================================================================\")\n",
    "        print(\"All book were analyzed\")\n",
    "    except NoSuchElementException as nse:\n",
    "        print(nse)\n",
    "        print(\"-----\")\n",
    "        print(str(nse))\n",
    "        print(\"-----\")\n",
    "        print(nse.args)\n",
    "        print(\"=====\")\n",
    "except TimeoutException as toe:\n",
    "    print(toe)\n",
    "    print(\"-----\")\n",
    "    print(str(toe))\n",
    "    print(\"-----\")\n",
    "    print(toe.args)\n",
    "finally:\n",
    "    if(Debug):\n",
    "        delete_table(\"historical\", conn)\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
